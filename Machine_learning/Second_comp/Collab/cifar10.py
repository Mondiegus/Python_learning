# -*- coding: utf-8 -*-
"""cifar10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j_7sgkrEoAc9VNl9Qo69j-Ub7iGkP4LE
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import os

from tensorflow.python.keras.datasets import cifar10
from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D
from tensorflow.python.keras.utils import to_categorical

import numpy as np
np.random.seed(0)

import matplotlib.pyplot as plt
# %matplotlib inline



(X_train, Y_train), (X_test, y_test) = cifar10.load_data()
X_train.shape, X_test.shape

plt.figure(figsize=(10,10))
for idx in range(25):
    plt.subplot(5,5,idx+1)
    plt.imshow(X_train[idx], cmap='gray')
    plt.title('Class: {}'.format(Y_train[idx]))
    plt.tight_layout()

img_rows, img_cols = X_train.shape[1], X_train.shape[2]

num_channels = 3
X_train = X_train.reshape(-1, img_rows, img_cols, num_channels)
X_test = X_test.reshape(-1, img_rows, img_cols, num_channels)

input_shape = (img_rows, img_cols, num_channels)

X_train.shape, X_test.shape

if np.max(X_train) >1: X_train = X_train / 255
if np.max(X_test) >1: X_test = X_test / 255

if len(Y_train.shape) == 2:
    Y_train = Y_train.reshape(-1)
    y_test = y_test.reshape(-1)
    
if len(Y_train.shape) == 1:
    num_classes = len(set(Y_train))
    Y_train = to_categorical(Y_train, num_classes)
    y_test = to_categorical(y_test, num_classes)
Y_train.shape, y_test.shape

resolver = tf.distribute.cluster_resolver.TPUClusterResolver()
tf.config.experimental_connect_to_host(resolver.master())
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)
with strategy.scope():
  model = Sequential([
    Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', input_shape = input_shape),
    Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu'),
    MaxPool2D(pool_size = (2, 2)),
    Dropout(0.25),
    
    
    Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'),
    Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'),
    MaxPool2D(pool_size = (2, 2)),
    Dropout(0.25),

    Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu'),
    MaxPool2D(pool_size = (2, 2)),
    Dropout(0.25),
    
    Flatten(),
    
    Dense(1024, activation = 'relu'),
    Dropout(0.5),
    Dense(num_classes, activation = 'softmax')
])
  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
  model.fit(
    X_train, Y_train,
    batch_size=128*8,
    steps_per_epoch=48,
    epochs=20)

TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']
tf.logging.set_verbosity(tf.logging.INFO)

tpu_model = tf.contrib.tpu.keras_to_tpu_model(
  model,
  strategy = tf.contrib.tpu.TPUDistributionStrategy(
    tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))



model.evaluate(X_test, y_test)